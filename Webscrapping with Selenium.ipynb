{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location, company_name,\n",
    "experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore”\n",
    "in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- All of the above steps have to be done in code. No step is to be done manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the Webdriver\n",
    "driver = webdriver.Chrome(\"C:\\\\chromedriver_win32\\\\chromedriver\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giving the Input Link\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sending Keyword 'Data Analyst' in search\n",
    "driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Analyst\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputing Location Bangalore\n",
    "driver.find_element_by_id(\"qsb-location-sugg\").send_keys(\"Bangalore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking Search Button\n",
    "driver.find_element_by_xpath(\"//div[@class='search-btn']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing Data from driver page source as Soup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_title = []\n",
    "Company_name = []\n",
    "for i in soup.find_all('a',class_=\"title fw500 ellipsis\")[:10]:\n",
    "    Job_title.append(i.text)\n",
    "for i in soup.find_all('div',class_=\"mt-7 companyInfo subheading lh16\")[:10]:\n",
    "    Company_name.append(i.text)\n",
    "Link = []\n",
    "for i in soup.find_all('a',class_=\"title fw500 ellipsis\")[:10]:\n",
    "    Link.append(i[\"href\"])\n",
    "\n",
    "Years = []\n",
    "Salary = []\n",
    "Location = []\n",
    "\n",
    "# Creating Indexes to capture 1st, 2nd and 3rd items from list iteratively. Using Arithmetic Progression create index numbers\n",
    "A = []\n",
    "for i in range(10):\n",
    "    A.append(0+i*3)   \n",
    "B = []\n",
    "for i in range(10):\n",
    "    B.append(1+i*3)\n",
    "C = []\n",
    "for i in range(10):\n",
    "    C.append(2+i*3)\n",
    "\n",
    "# Contains the years, salary and Location in one List. Using the Index lists A, B, C to capture them iteratively.\n",
    "for i,j in enumerate(soup.find_all('span',class_=\"ellipsis fleft fs12 lh16\")[:30]):\n",
    "    if i in A:\n",
    "        Years.append(j.text)\n",
    "    elif i in B:\n",
    "        Salary.append(j.text)\n",
    "    elif i in C:\n",
    "        Location.append(j.text)\n",
    "\n",
    "df = pd.DataFrame({}) \n",
    "df[\"Job Title\"] = Job_title\n",
    "df[\"Company Name\"] = Company_name\n",
    "df[\"Experience Required\"] = Years\n",
    "df[\"Salary\"] = Salary\n",
    "df[\"Location\"] = Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst Jobs in Bangalore\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst - SAP</td>\n",
       "      <td>Boston Scientific Corporation</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune, Delhi, Bengaluru, Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring Data Analysts on Contract</td>\n",
       "      <td>Flipkart Internet Private Limited4.2(2710 Revi...</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>3,00,000 - 6,00,000 PA.</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Schneider Electric4.2(1219 Reviews)</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Shell India Markets Private Limited4.2(524 Rev...</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst -Azure Data lake, Azure Data factory</td>\n",
       "      <td>Mindtree Limited3.9(1386 Reviews)</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business / Data Analyst</td>\n",
       "      <td>IBM India Pvt. Limited4.1(8806 Reviews)</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - O2C - Bangalore</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD4.0(944 Reviews)</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>3,25,000 - 4,50,000 PA.</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Intern Data Analyst</td>\n",
       "      <td>Outsource Big Data</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NiFi Data Analyst</td>\n",
       "      <td>Capgemini Technology Services India Limited3.5...</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Reliance Jio Infocomm Ltd.4.0(8820 Reviews)</td>\n",
       "      <td>8-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                                 Data Analyst - SAP   \n",
       "1                   Hiring Data Analysts on Contract   \n",
       "2                                Senior Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4  Data Analyst -Azure Data lake, Azure Data factory   \n",
       "5                            Business / Data Analyst   \n",
       "6                     Data Analyst - O2C - Bangalore   \n",
       "7                                Intern Data Analyst   \n",
       "8                                  NiFi Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                        Company Name Experience Required  \\\n",
       "0                      Boston Scientific Corporation             3-5 Yrs   \n",
       "1  Flipkart Internet Private Limited4.2(2710 Revi...             2-5 Yrs   \n",
       "2                Schneider Electric4.2(1219 Reviews)             2-5 Yrs   \n",
       "3  Shell India Markets Private Limited4.2(524 Rev...             5-8 Yrs   \n",
       "4                  Mindtree Limited3.9(1386 Reviews)             5-9 Yrs   \n",
       "5            IBM India Pvt. Limited4.1(8806 Reviews)             2-4 Yrs   \n",
       "6             RANDSTAD INDIA PVT LTD4.0(944 Reviews)             2-4 Yrs   \n",
       "7                                 Outsource Big Data             0-1 Yrs   \n",
       "8  Capgemini Technology Services India Limited3.5...             4-6 Yrs   \n",
       "9        Reliance Jio Infocomm Ltd.4.0(8820 Reviews)             8-9 Yrs   \n",
       "\n",
       "                    Salary                             Location  \n",
       "0            Not disclosed      Pune, Delhi, Bengaluru, Gurgaon  \n",
       "1  3,00,000 - 6,00,000 PA.                            Bengaluru  \n",
       "2            Not disclosed                Bengaluru / Bangalore  \n",
       "3            Not disclosed                            Bengaluru  \n",
       "4            Not disclosed  Chennai, Pune, Bengaluru, Hyderabad  \n",
       "5            Not disclosed                            Bengaluru  \n",
       "6  3,25,000 - 4,50,000 PA.                            Bengaluru  \n",
       "7            Not disclosed                            Bengaluru  \n",
       "8            Not disclosed                            Bengaluru  \n",
       "9            Not disclosed                            Bengaluru  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data Analyst Jobs in Bangalore\\n\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field and enter\n",
    "“Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "Note- 1. All of the above steps have to be done in code. No step is to be done\n",
    "manually.\n",
    "Please note that you have to scrape full job description. For that you may have to\n",
    "open each job separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(\"C:\\\\chromedriver_win32\\\\chromedriver\")\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Scientist\") \n",
    "driver.find_element_by_id(\"qsb-location-sugg\").send_keys(\"Bangalore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//div[@class='search-btn']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_title = []\n",
    "Company_name = []\n",
    "for i in soup.find_all('a',class_=\"title fw500 ellipsis\")[:10]:\n",
    "    Job_title.append(i.text)\n",
    "for i in soup.find_all('div',class_=\"mt-7 companyInfo subheading lh16\")[:10]:\n",
    "    Company_name.append(i.text)\n",
    "Link = []\n",
    "for i in soup.find_all('a',class_=\"title fw500 ellipsis\")[:10]:\n",
    "    Link.append(i[\"href\"])\n",
    "\n",
    "Years = []\n",
    "Salary = []\n",
    "Location = []\n",
    "\n",
    "# Creating Indexes to capture 1st, 2nd and 3rd items from list iteratively. Using Arithmetic Progression create index numbers\n",
    "A = []\n",
    "for i in range(10):\n",
    "    A.append(0+i*3)\n",
    "B = []\n",
    "for i in range(10):\n",
    "    B.append(1+i*3)\n",
    "C = []\n",
    "for i in range(10):\n",
    "    C.append(2+i*3)\n",
    "    \n",
    "# Contains the years, salary and Location in one List. Using the Index lists A, B, C to capture them iteratively.\n",
    "for i,j in enumerate(soup.find_all('span',class_=\"ellipsis fleft fs12 lh16\")[:30]):\n",
    "    if i in A:\n",
    "        Years.append(j.text)\n",
    "    elif i in B:\n",
    "        Salary.append(j.text)\n",
    "    elif i in C:\n",
    "        Location.append(j.text)\n",
    "\n",
    "df2 = pd.DataFrame({}) \n",
    "df2[\"Job Title\"] = Job_title\n",
    "df2[\"Company Name\"] = Company_name\n",
    "df2[\"Experience Required\"] = Years\n",
    "df2[\"Salary\"] = Salary\n",
    "df2[\"Location\"] = Location\n",
    "df2[\"Job_desc_Link\"] = Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_desc_Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>3,00,000 - 4,25,000 PA.</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>https://www.naukri.com/job-listings-lead-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED3.9(119 Reviews)</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Atos Syntel Private Limited3.6(1786 Reviews)</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Chennai, Pune, Mumbai, Bengaluru</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Tech Mahindra Ltd.3.6(10444 Reviews)</td>\n",
       "      <td>12-20 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>https://www.naukri.com/job-listings-opening-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Tech Mahindra Ltd.3.6(10444 Reviews)</td>\n",
       "      <td>12-20 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>https://www.naukri.com/job-listings-opening-fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.3.1(73 Reviews)</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>https://www.naukri.com/job-listings-senior-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist and Senior Data Scientist Acade...</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD4.0(944 Reviews)</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>8,00,000 - 13,00,000 PA.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>https://www.naukri.com/job-listings-data-scien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0              Data Scientist/Data Analyst-immediate   \n",
       "1  Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "2  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "3    Data Scientist - Machine Learning (Commerce BU)   \n",
       "4                                     Data Scientist   \n",
       "5     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "6     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "7             Senior Data Scientist - NLP/ Python/ R   \n",
       "8  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "9  Data Scientist and Senior Data Scientist Acade...   \n",
       "\n",
       "                                        Company Name Experience Required  \\\n",
       "0                 Inflexion Analytix Private Limited             1-2 Yrs   \n",
       "1                       Wrackle Technologies Pvt Ltd             3-8 Yrs   \n",
       "2                       Wrackle Technologies Pvt Ltd            6-11 Yrs   \n",
       "3  BLUE YONDER INDIA PRIVATE LIMITED3.9(119 Reviews)             4-6 Yrs   \n",
       "4       Atos Syntel Private Limited3.6(1786 Reviews)           12-18 Yrs   \n",
       "5               Tech Mahindra Ltd.3.6(10444 Reviews)           12-20 Yrs   \n",
       "6               Tech Mahindra Ltd.3.6(10444 Reviews)           12-20 Yrs   \n",
       "7                                 AVI Consulting LLP             4-9 Yrs   \n",
       "8                            CES Ltd.3.1(73 Reviews)             2-7 Yrs   \n",
       "9             RANDSTAD INDIA PVT LTD4.0(944 Reviews)             2-5 Yrs   \n",
       "\n",
       "                     Salary  \\\n",
       "0   3,00,000 - 4,25,000 PA.   \n",
       "1             Not disclosed   \n",
       "2             Not disclosed   \n",
       "3             Not disclosed   \n",
       "4             Not disclosed   \n",
       "5             Not disclosed   \n",
       "6             Not disclosed   \n",
       "7             Not disclosed   \n",
       "8  7,00,000 - 15,00,000 PA.   \n",
       "9  8,00,000 - 13,00,000 PA.   \n",
       "\n",
       "                                            Location  \\\n",
       "0                Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                                          Bengaluru   \n",
       "4                   Chennai, Pune, Mumbai, Bengaluru   \n",
       "5                                    Pune, Bengaluru   \n",
       "6                                    Pune, Bengaluru   \n",
       "7                               Bengaluru, Hyderabad   \n",
       "8  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "9                                          Bengaluru   \n",
       "\n",
       "                                       Job_desc_Link  \n",
       "0  https://www.naukri.com/job-listings-data-scien...  \n",
       "1  https://www.naukri.com/job-listings-data-scien...  \n",
       "2  https://www.naukri.com/job-listings-lead-data-...  \n",
       "3  https://www.naukri.com/job-listings-data-scien...  \n",
       "4  https://www.naukri.com/job-listings-data-scien...  \n",
       "5  https://www.naukri.com/job-listings-opening-fo...  \n",
       "6  https://www.naukri.com/job-listings-opening-fo...  \n",
       "7  https://www.naukri.com/job-listings-senior-dat...  \n",
       "8  https://www.naukri.com/job-listings-senior-dat...  \n",
       "9  https://www.naukri.com/job-listings-data-scien...  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capturing Job Description Full one by one \n",
    "Job_Desc_full = []\n",
    "for i in Link:\n",
    "    driver.get(i)\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    for i in soup.find_all('section',class_=\"job-desc\"):\n",
    "        job_desc_text = i.find(\"div\").text\n",
    "    Job_Desc_full.append(job_desc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Job descriptionDear CandidateSchedule a Telephonic Interview ( Please call for confirmation) : Mon- Sat from 11:00am to 5:00pm only. OR Walk-In to the Corporate office between Monday to Friday from 11:00am to 5:00pmContact person :  Manigandan -+91 7299917200 Shantha +91 9790993237Aishwaria 9427329576 Greetings from CAIA !A great opportunity to enter the world of future technologies - Data Science, Analytics, AI, Data Visualization Applications invited from all Freshers and experienced candidates aspiring to make a career in Artificial Intelligence and Advanced Analytics and Data Science. In case you are trying to shift your career to Analytics and/or AI domain please do connect with us to know more.What is needed from you?- An Educational background in any one of the following- BE/B.Tech, ME/M Tech, MSc, BSc/MSc Maths and Statistics, B Com, BCA, BSc CS, BSC IT, MSC IT, MCA- Skills relating to Mathematics/Statistics.- Natural passion towards numbers, business, coding, Analytics and Artificial Intelligence, Machine Learning, visualization- Good verbal and written communication skills- Ability to understand domains in businesses across various sectors- Freshers who wish to start their career in Analytics and AI and professionals who wish to up skill or change their domain to analytics and emerging technologies are free to apply.Selection procedure includes- Online Aptitude Test- Logical Ability Test / Written TestOn being shortlisted, you will be have to undergo a one-one discussion with our counsellor for further evaluation and processing of your Resume.What you can expect from us?You will get trained on the following modules for a period of 12-14 weeks:-SQL & PLSQL-Data Wrangling using Python-Statistics for Machine Learning,-Artificial Intelligence, Data Interpretation-Supervised & Unsupervised Learning,-NLP & Deep Learning-Cloud Data Lake -Business intelligence & Data Visualization-Simulation ProjectsWhat is the expected Outcome?At the end of the Training you are expected to be well versed with the following:- Analysis of large and complex data sets from multiple sources- Development and evaluation of data analytics models, algorithms and solutions- Understanding/implementation of ML algorithms, performance tuning and reporting- Implementation of algorithms to mine targeted data and the ability to convert data into a business story- Translation of business requirements into technical requirements; Data extraction, preparation and transformation- Identification, development and implementation of statistical techniques and algorithms that address business challenges and adds value to the organisation- Requirement Analysis and communication of findings in the form of a meaningful story with the stakeholdersCenter for Artificial Intelligence & Advanced Analytics (CAIA) focuses on the following:1. Global Research on emerging trends, technologies and applications in AI and Advanced Analytics2. Advanced Training programs for readying the future ready workforce3. Solutions to herald the futuristic lifestyle and workspaces in the field of AI and Data Science.http://www.centerforaia.com/Center for Artificial Intelligence and Advanced Analytics (Center for AIA) is the brainchild of experienced and visionary alumni of IIT Madras and Bombay. Digital leaders 5F World and Systech Solutions have joined hands to create a venture for architecting the future of society, workforce, governments and businesses. 5F World specializes in designing solutions around digital platforms and Systech Solutions has an expertise in architecting Artificial Intelligence and Advanced Analytics solutions for Fortune 500 companies through specialized programmed.5F World5F World is a leader in digital transformational journeys and has brought together the best minds in industry, academia and technology domains to develop a unique framework to transform stakeholder journeys through innovation and digitalization of businesses and education institutions.Systech SolutionsSystech Solutions is a leading organisation in Data Strategy, Management & Analytics services provider with deep technology expertise and over 20 years of industry experience. Systech Solutions helps empower clients with innovative, data-driven solutions to reimagine their enterprise and has forged partnerships with industry-leading technology providers to develop a full spectrum of data services.  Website http://www.centerforaia.com/  https://inflexion-analytix-private-limited.business.site/?m=true Contact Person Manigandan /Shantha/AishwariaPhone Number7299917200/ 9790993237 / 9427329576Emailmanigandan@centerforaia.com',\n",
       " 'Data Scientist - Data Mining/ Machine Learning/ Statistical AnalysisRequirements :- 3-9 years of strong experience in data mining, machine learning, and statistical analysis.- BS/MS/Ph.D. in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)- Ability to lead and deliver in a fast-paced start-up environment.- Fluency in tools such as Matlab, Python, etc.- Strong intuition for data and Keen aptitude on large scale data analysis- Excellent written and verbal communication skills.- Ability to collaborate across teams and strong interpersonal skills.',\n",
       " 'Roles and ResponsibilitiesRequirements :- 6-9 years of strong experience in data mining, machine learning and statistical analysis.- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)- Ability to lead and deliver in a fast-paced start-up environment.- Fluency in tools such as Python/ R/ Matlab etc.- Strong intuition for data and Keen aptitude on large scale data analysis- Excellent written and verbal communication skills.- Ability to collaborate across teams and strong interpersonal skills.',\n",
       " 'Roles and ResponsibilitiesRequirements :- 6-9 years of strong experience in data mining, machine learning and statistical analysis.- BS/ MS/ PhD in Computer Science, Statistics, Applied Math, or related areas from Premier institutes ( only IITs / IISc / BITS / Top NITs or top US university should apply)- Ability to lead and deliver in a fast-paced start-up environment.- Fluency in tools such as Python/ R/ Matlab etc.- Strong intuition for data and Keen aptitude on large scale data analysis- Excellent written and verbal communication skills.- Ability to collaborate across teams and strong interpersonal skills.',\n",
       " ' Working experience in Artificial Intelligence, Python, R, Machine Learning Experience in data mining, Strong math skills (e.g. statistics, algebra) Strong programming skills in: R, Python and familiarity with Java, Scala, C - DB/NoSql - MongoDB, Neo4J, MySql. Cassandra, DynamoDB, Redshift Experience on Hadoop Map reduce, Pig, Hive, Mahout and Apache Spark, H20 Strong experience in Data warehousing, ETL, BI (e.g. Tableau, Power BI) and Data Visualization tools (matplotlib, D3.js, Plotly.js, Shiny etc) Experience with Deep Learning tools Tensorflow, Theano, Caffe etc. - Elastic Search, NLP background and Machine Learning Platforms Experienced in deployment of High performance, Scalable Big Data Hadoop clusters and Web applications on cloud infrastructure (Azure, AWS, Bluemix etc)  Experience in neural networks, regression, classification and clustering  Deep industry knowledge on any of the following: Banking, Insurance, Retail Manufacturing  Deep understanding of Statistical algorithms: Linear and Non-Linear models, classification problem, optimization techniques, Market mix models, A/B Testing and campaign management, Feature ranking/selection techniques, supervised/unsupervised learning, Collaborative filtering, Apriori Market Basket analysis, SVM, Gradient boosting, Survival analysis etc. To help designing, innovating and building our next generation ML architecture Full time programming experience within an operation or technical department. Identify valuable data sources and automate collection processes Undertake pre-processing of structured and unstructured data Analyze large amounts of information to discover trends and patterns Build predictive models and machine-learning algorithms Combine models through ensemble modelling Present information using data visualization techniques Propose solutions and strategies to business challenges Collaborate with engineering and product development teams Mentor others in the use of AI/Machine Learning',\n",
       " ' Working experience in Artificial Intelligence, Python, R, Machine Learning Experience in data mining, Strong math skills (e.g. statistics, algebra) Strong programming skills in: R, Python and familiarity with Java, Scala, C - DB/NoSql - MongoDB, Neo4J, MySql. Cassandra, DynamoDB, Redshift Experience on Hadoop Map reduce, Pig, Hive, Mahout and Apache Spark, H20 Strong experience in Data warehousing, ETL, BI (e.g. Tableau, Power BI) and Data Visualization tools (matplotlib, D3.js, Plotly.js, Shiny etc) Experience with Deep Learning tools Tensorflow, Theano, Caffe etc. - Elastic Search, NLP background and Machine Learning Platforms Experienced in deployment of High performance, Scalable Big Data Hadoop clusters and Web applications on cloud infrastructure (Azure, AWS, Bluemix etc)  Experience in neural networks, regression, classification and clustering  Deep industry knowledge on any of the following: Banking, Insurance, Retail Manufacturing  Deep understanding of Statistical algorithms: Linear and Non-Linear models, classification problem, optimization techniques, Market mix models, A/B Testing and campaign management, Feature ranking/selection techniques, supervised/unsupervised learning, Collaborative filtering, Apriori Market Basket analysis, SVM, Gradient boosting, Survival analysis etc. To help designing, innovating and building our next generation ML architecture Full time programming experience within an operation or technical department. Identify valuable data sources and automate collection processes Undertake pre-processing of structured and unstructured data Analyze large amounts of information to discover trends and patterns Build predictive models and machine-learning algorithms Combine models through ensemble modelling Present information using data visualization techniques Propose solutions and strategies to business challenges Collaborate with engineering and product development teams Mentor others in the use of AI/Machine Learning',\n",
       " ' Working experience in Artificial Intelligence, Python, R, Machine Learning Experience in data mining, Strong math skills (e.g. statistics, algebra) Strong programming skills in: R, Python and familiarity with Java, Scala, C - DB/NoSql - MongoDB, Neo4J, MySql. Cassandra, DynamoDB, Redshift Experience on Hadoop Map reduce, Pig, Hive, Mahout and Apache Spark, H20 Strong experience in Data warehousing, ETL, BI (e.g. Tableau, Power BI) and Data Visualization tools (matplotlib, D3.js, Plotly.js, Shiny etc) Experience with Deep Learning tools Tensorflow, Theano, Caffe etc. - Elastic Search, NLP background and Machine Learning Platforms Experienced in deployment of High performance, Scalable Big Data Hadoop clusters and Web applications on cloud infrastructure (Azure, AWS, Bluemix etc)  Experience in neural networks, regression, classification and clustering  Deep industry knowledge on any of the following: Banking, Insurance, Retail Manufacturing  Deep understanding of Statistical algorithms: Linear and Non-Linear models, classification problem, optimization techniques, Market mix models, A/B Testing and campaign management, Feature ranking/selection techniques, supervised/unsupervised learning, Collaborative filtering, Apriori Market Basket analysis, SVM, Gradient boosting, Survival analysis etc. To help designing, innovating and building our next generation ML architecture Full time programming experience within an operation or technical department. Identify valuable data sources and automate collection processes Undertake pre-processing of structured and unstructured data Analyze large amounts of information to discover trends and patterns Build predictive models and machine-learning algorithms Combine models through ensemble modelling Present information using data visualization techniques Propose solutions and strategies to business challenges Collaborate with engineering and product development teams Mentor others in the use of AI/Machine Learning',\n",
       " 'Roles and ResponsibilitiesSkill : NLP,Semantic model, NER model, Deep LearningNotice : who can join in a month maxJob description :- 5+ years of experience using analytical toolslanguages like Python & R on large scale data- Must have Semantic model & NER experience- Experience working with pre-trained models, awareness of state-of-art in embeddings and applicability for use cases- Experience on Deep Learning for Image processing, Video analytics will be a plus- Must have strong experience in NLPNLGNLU applications using any popular Deep learning frameworks like Open CV, PyTorch, Theano, Tensor Flow, Caffe. Should have implemented solutions for industry use cases.- Demonstrated ability to engage with client stakeholders at multiple levels and provide consultative solutioning across different domains- Deep knowledge of techniques such as Linear Regression, gradient descent, Logistic Regression, Forecasting, Cluster analysis, Decision trees, Linear Optimization, Text Mining etc.- Must have experience in doing POCs - Strong applied fundamentals in data management, parallel computing and distributed systems; experience in productionizing & retraining models- Ability to guide and mentor teams of associates on solution development and approaches- Broad knowledge of fundamentals and state-of-the-art in NLP and machine learning- Coding skills in one or more programming languages such as Python, Scala, Java, C, C++- Expert high level of understanding on language semantic concepts & data standardization- Proven track record of successful models and practical implementation- Hands-on experience with popular ML frameworks such as TensorFlow- Experience with application development practices at scale, from problem definition to deployment.- Familiarity with Cloud services such as AWS, SageMaker etc. is considered a plus- Develop and apply Statistical Modeling techniques (e.g. Bayesian models and deep neural networks), optimization methods, and other ML techniques to different applications- Knowledge in Machine Learning techniques in entity resolution, common speech products or text search domain ',\n",
       " 'Roles and Responsibilities  Must have strong Python Programming SkillsStrong analytical & algorithm development skillsLogical and Analytical skills must be really strongMust have worked in DeepLearning Efforts - Especially computer vision.Must have experinece with Object Detection - Custom model training for Object detection Should have experience with atleast one or more of these - Tensorflow, Keras, PyTorchPrimary Skills - Python + tensorflow -  Keras / PyTorch, OpenCV Perks and Benefits Kindly share your resume to kandavelkumar.lakshmanan @cesltd.com ',\n",
       " \"We are hiring Data Scientist and Senior Data Scientist Academic Operations for our leading EdTech Client.Call/WhatsApp- Amit-9379292728Email: amitkumar.s@randstad.inor Fill the google form - https://tinyurl.com/JobAppForm4Job Responsibilities:Your primary job responsibility will include (and not limited to):Own the student's learning outcomes by providing them with support on the topics covered in thecurriculum. Involve in the residency class room sessions to facilitate lectures and lab sessions Be the first point contact for participants for academic queries and manage discussiongroups Monitor participants academic performance and make learning interventions in theform of remedial sessions, coaching and mentoringCoordinate with faculty to create best in class learning material - video, reading material,assignments, exams Design and conduct examinations to measure the learning outcome of participants Identify & Solve interesting problems involving rich datasets in various domains.Accordingly, create capstone projects on the evolving use cases in the industry Identify key emerging trends in the industry and maintain a rich reference material Assist program director and senior operations and academics managers in planningon-campus sessions, preparing schedules, evaluation and grading Identify key reporting metric sand create dashboards to enable quick decision makingAutomation of manual data collection, data cleansing and exploratory data analysis Create and maintain business and technical requirements Identify technical solutions and perform feasibility analysis Create technical roadmaps for the operations Team Manage, identify and suggest processes for smoother program management toensure a consistent and trouble free learning experience Coordinate with IT and Admin to ensure smooth execution at various locations Travel to other cities if required to manage residenciesRelevant Background: Graduate with an exceptional academic track record Competency: (Top 3)1. Passion for learning and having great learning outcomes2. Ability to multitask and coordinate with multiple stakeholders3. Excellent knowledge in python, tableau and ML concepts\"]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Job Description Full Data for 10 jobs\n",
    "Job_Desc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(\"Job_desc_Link\",axis=1)\n",
    "df2[\"Job Description Full\"] = Job_Desc_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Sceintist Jobs in Bangalore with full job description\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Description Full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist/Data Analyst-immediate</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "      <td>3,00,000 - 4,25,000 PA.</td>\n",
       "      <td>Chennai, Pune, Bengaluru, Hyderabad</td>\n",
       "      <td>Job descriptionDear CandidateSchedule a Telep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Data Scientist - Data Mining/ Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and ResponsibilitiesRequirements :- 6-9 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning (Commerce BU)</td>\n",
       "      <td>BLUE YONDER INDIA PRIVATE LIMITED3.9(119 Reviews)</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and ResponsibilitiesRequirements :- 6-9 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Atos Syntel Private Limited3.6(1786 Reviews)</td>\n",
       "      <td>12-18 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Chennai, Pune, Mumbai, Bengaluru</td>\n",
       "      <td>Working experience in Artificial Intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Tech Mahindra Ltd.3.6(10444 Reviews)</td>\n",
       "      <td>12-20 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>Working experience in Artificial Intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Opening For Sr. Data Scientist @ Tech Mahindra</td>\n",
       "      <td>Tech Mahindra Ltd.3.6(10444 Reviews)</td>\n",
       "      <td>12-20 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Pune, Bengaluru</td>\n",
       "      <td>Working experience in Artificial Intelligence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "      <td>Not disclosed</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>Roles and ResponsibilitiesSkill : NLP,Semantic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.3.1(73 Reviews)</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>7,00,000 - 15,00,000 PA.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>Roles and Responsibilities  Must have strong P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist and Senior Data Scientist Acade...</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD4.0(944 Reviews)</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>8,00,000 - 13,00,000 PA.</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are hiring Data Scientist and Senior Data S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0              Data Scientist/Data Analyst-immediate   \n",
       "1  Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "2  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "3    Data Scientist - Machine Learning (Commerce BU)   \n",
       "4                                     Data Scientist   \n",
       "5     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "6     Opening For Sr. Data Scientist @ Tech Mahindra   \n",
       "7             Senior Data Scientist - NLP/ Python/ R   \n",
       "8  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "9  Data Scientist and Senior Data Scientist Acade...   \n",
       "\n",
       "                                        Company Name Experience Required  \\\n",
       "0                 Inflexion Analytix Private Limited             1-2 Yrs   \n",
       "1                       Wrackle Technologies Pvt Ltd             3-8 Yrs   \n",
       "2                       Wrackle Technologies Pvt Ltd            6-11 Yrs   \n",
       "3  BLUE YONDER INDIA PRIVATE LIMITED3.9(119 Reviews)             4-6 Yrs   \n",
       "4       Atos Syntel Private Limited3.6(1786 Reviews)           12-18 Yrs   \n",
       "5               Tech Mahindra Ltd.3.6(10444 Reviews)           12-20 Yrs   \n",
       "6               Tech Mahindra Ltd.3.6(10444 Reviews)           12-20 Yrs   \n",
       "7                                 AVI Consulting LLP             4-9 Yrs   \n",
       "8                            CES Ltd.3.1(73 Reviews)             2-7 Yrs   \n",
       "9             RANDSTAD INDIA PVT LTD4.0(944 Reviews)             2-5 Yrs   \n",
       "\n",
       "                     Salary  \\\n",
       "0   3,00,000 - 4,25,000 PA.   \n",
       "1             Not disclosed   \n",
       "2             Not disclosed   \n",
       "3             Not disclosed   \n",
       "4             Not disclosed   \n",
       "5             Not disclosed   \n",
       "6             Not disclosed   \n",
       "7             Not disclosed   \n",
       "8  7,00,000 - 15,00,000 PA.   \n",
       "9  8,00,000 - 13,00,000 PA.   \n",
       "\n",
       "                                            Location  \\\n",
       "0                Chennai, Pune, Bengaluru, Hyderabad   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                                          Bengaluru   \n",
       "4                   Chennai, Pune, Mumbai, Bengaluru   \n",
       "5                                    Pune, Bengaluru   \n",
       "6                                    Pune, Bengaluru   \n",
       "7                               Bengaluru, Hyderabad   \n",
       "8  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "9                                          Bengaluru   \n",
       "\n",
       "                                Job Description Full  \n",
       "0   Job descriptionDear CandidateSchedule a Telep...  \n",
       "1  Data Scientist - Data Mining/ Machine Learning...  \n",
       "2  Roles and ResponsibilitiesRequirements :- 6-9 ...  \n",
       "3  Roles and ResponsibilitiesRequirements :- 6-9 ...  \n",
       "4   Working experience in Artificial Intelligence...  \n",
       "5   Working experience in Artificial Intelligence...  \n",
       "6   Working experience in Artificial Intelligence...  \n",
       "7  Roles and ResponsibilitiesSkill : NLP,Semantic...  \n",
       "8  Roles and Responsibilities  Must have strong P...  \n",
       "9  We are hiring Data Scientist and Senior Data S...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data Sceintist Jobs in Bangalore with full job description\")\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for this Entire Process\n",
    "def Job_finder_Naukri():\n",
    "    driver = webdriver.Chrome(\"C:\\\\chromedriver_win32\\\\chromedriver\")\n",
    "    driver.get('https://www.naukri.com/')\n",
    "    driver.find_element_by_id(\"qsb-keyword-sugg\").send_keys(\"Data Scientist\") \n",
    "    driver.find_element_by_id(\"qsb-location-sugg\").send_keys(\"Bangalore\") \n",
    "    driver.find_element_by_xpath(\"//div[@class='search-btn']\").click()\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    Job_title = []\n",
    "    Company_name = []\n",
    "    for i in soup.find_all('a',class_=\"title fw500 ellipsis\")[:10]:\n",
    "        Job_title.append(i.text)\n",
    "    for i in soup.find_all('div',class_=\"mt-7 companyInfo subheading lh16\")[:10]:\n",
    "        Company_name.append(i.text)\n",
    "    Link = []\n",
    "    for i in soup.find_all('a',class_=\"title fw500 ellipsis\")[:10]:\n",
    "        Link.append(i[\"href\"])\n",
    "\n",
    "    Years = []\n",
    "    Salary = []\n",
    "    Location = []\n",
    "    A = []\n",
    "    for i in range(10):\n",
    "        A.append(0+i*3)\n",
    "    B = []\n",
    "    for i in range(10):\n",
    "        B.append(1+i*3)\n",
    "    C = []\n",
    "    for i in range(10):\n",
    "        C.append(2+i*3)\n",
    "\n",
    "    for i,j in enumerate(soup.find_all('span',class_=\"ellipsis fleft fs12 lh16\")[:30]):\n",
    "        if i in A:\n",
    "            Years.append(j.text)\n",
    "        elif i in B:\n",
    "            Salary.append(j.text)\n",
    "        elif i in C:\n",
    "            Location.append(j.text)\n",
    "\n",
    "    Job_Desc_full = []\n",
    "    for i in Link:\n",
    "        driver.get(i)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        for i in soup.find_all('section',class_=\"job-desc\"):\n",
    "            job_desc_text = i.find(\"div\").text\n",
    "        Job_Desc_full.append(job_desc_text)\n",
    "    df = pd.DataFrame({}) \n",
    "    df[\"Job Title\"] = Job_title\n",
    "    df[\"Company Name\"] = Company_name\n",
    "    df[\"Experience Required\"] = Years\n",
    "    df[\"Salary\"] = Salary\n",
    "    df[\"Location\"] = Location\n",
    "    df[\"Job Desc Full\"] = Job_Desc_full\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_product(product):   \n",
    "    driver = webdriver.Chrome(\"C:\\\\chromedriver_win32\\\\chromedriver\")\n",
    "    driver.get('https://www.flipkart.com/')\n",
    "    driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\").click()\n",
    "    driver.find_element_by_xpath(\"//input[@class='_3704LK']\").send_keys(product)\n",
    "    driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\").click()\n",
    "    time.sleep(2)   # Using sleep to give driver time to load\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    Brand = []\n",
    "    for i in soup.find_all('div',class_=\"_2WkVRV\"):\n",
    "        Brand.append(i.text)\n",
    "    Product_Desc = []\n",
    "    for i in soup.find_all('a',class_=\"IRpwTa\"):\n",
    "        Product_Desc.append(i.text)\n",
    "    Price = []\n",
    "    for i in soup.find_all('div',class_=\"_30jeq3\"):\n",
    "        Price.append(i.text)\n",
    "    Discount = []\n",
    "    for i in soup.find_all('div',class_=\"_3Ay6Sb\"):\n",
    "        Discount.append(i.text)\n",
    "    data = pd.DataFrame({})\n",
    "    data[\"Brand\"] = Brand\n",
    "    data[\"Product Descr\"] = Product_Desc\n",
    "    data[\"Price\"] = Price[:len(Brand)]\n",
    "    data[\"Discount %\"] = Discount[:len(Brand)]\n",
    "    # Go to Next Page\n",
    "    nxt_button=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    if nxt_button.text=='Next':\n",
    "        nxt_button.click()\n",
    "        \n",
    "    # Capturing Data till length is 100\n",
    "    while len(data) < 100:\n",
    "        time.sleep(3)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        Brand = []\n",
    "        for i in soup.find_all('div',class_=\"_2WkVRV\"):\n",
    "            Brand.append(i.text)\n",
    "        Product_Desc = []\n",
    "        for i in soup.find_all('a',class_=\"IRpwTa\"):\n",
    "            Product_Desc.append(i.text)\n",
    "        Price = []\n",
    "        for i in soup.find_all('div',class_=\"_30jeq3\"):\n",
    "            Price.append(i.text)\n",
    "        Discount = []\n",
    "        for i in soup.find_all('div',class_=\"_3Ay6Sb\"):\n",
    "            Discount.append(i.text)\n",
    "        df = pd.DataFrame({})\n",
    "        df[\"Brand\"] = Brand\n",
    "        df[\"Product Descr\"] = Product_Desc\n",
    "        df[\"Price\"] = Price[:len(Brand)]\n",
    "        df[\"Discount %\"] = Discount[:len(Brand)]\n",
    "        data = data.append(df)\n",
    "        data = data.reset_index(drop=True)\n",
    "        nxt_button=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        if nxt_button.text=='Next':\n",
    "            nxt_button.click()\n",
    "        time.sleep(3) \n",
    "    return data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Sunglasses from Flipkart\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Descr</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Rectangular Sunglasses...</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹896</td>\n",
       "      <td>31% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Online Mantra</td>\n",
       "      <td>UV Protection Round, Aviator Sunglasses (Free ...</td>\n",
       "      <td>₹150</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Gansta</td>\n",
       "      <td>UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹284</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                      Product Descr Price  \\\n",
       "0   ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)  ₹499   \n",
       "1         Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "2         Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "3         Fastrack       UV Protection Aviator Sunglasses (Free Size)  ₹599   \n",
       "4   ROZZETTA CRAFT  UV Protection, Gradient Rectangular Sunglasses...  ₹404   \n",
       "..             ...                                                ...   ...   \n",
       "95        Fastrack              UV Protection Aviator Sunglasses (58)  ₹896   \n",
       "96   Online Mantra  UV Protection Round, Aviator Sunglasses (Free ...  ₹150   \n",
       "97          Gansta              UV Protection Aviator Sunglasses (57)  ₹284   \n",
       "98        Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹399   \n",
       "99  ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)  ₹499   \n",
       "\n",
       "   Discount %  \n",
       "0     77% off  \n",
       "1     37% off  \n",
       "2     37% off  \n",
       "3     33% off  \n",
       "4     79% off  \n",
       "..        ...  \n",
       "95    31% off  \n",
       "96    70% off  \n",
       "97    85% off  \n",
       "98    50% off  \n",
       "99    77% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"100 Sunglasses from Flipkart\")\n",
    "flipkart_product(\"Sunglasses\")     # Giving input Sunglasses to the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to\n",
    "go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC\n",
    "TSVZAXUHGREPBFGI&marketplace.\n",
    "These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flipkart_reviews():    \n",
    "    driver = webdriver.Chrome(\"C:\\\\chromedriver_win32\\\\chromedriver\")\n",
    "    driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace\")\n",
    "    \n",
    "    # Going to the Page where page contains all reviews. We can switch pages clicking NEXT.\n",
    "    reviewspage = driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']\")  \n",
    "    reviewspage.click()\n",
    "    reviews = []\n",
    "    review_summary = []\n",
    "    rating = []\n",
    "    # Capturing Data till length is 100\n",
    "    while len(reviews) < 100:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        for i in soup.find_all('div',class_=\"_3LWZlK _1BLPMq\"):\n",
    "            rating.append(i.text)\n",
    "        for i in soup.find_all('p',class_=\"_2-N8zT\"):\n",
    "            review_summary.append(i.text)\n",
    "        for i in soup.find_all('div',class_=\"t-ZTKy\"):   # Capturing full Reviews\n",
    "            reviews.append(i.text)\n",
    "        time.sleep(4)\n",
    "        # Going to Next Page\n",
    "        nxt_button=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "        if nxt_button.text=='NEXT':\n",
    "            nxt_button.click()\n",
    "        time.sleep(2)\n",
    "    df = pd.DataFrame({})\n",
    "    df[\"Review Summary\"] = review_summary\n",
    "    df[\"Review Full\"] = reviews\n",
    "    df[\"Rating\"] = rating\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flipkart 100 reviews\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Review Full</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.I’m am ver...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the MoneyThe iPhone 11 offe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Brilliant</td>\n",
       "      <td>I have migrated from OP 7pro... and trust me, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is my first ever I phone. Before this I w...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Great product</td>\n",
       "      <td>Well you all know the specifications . One of ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Review Summary                                        Review Full  \\\n",
       "0     Perfect product!  Amazing phone with great cameras and better ba...   \n",
       "1        Great product  Amazing Powerful and Durable Gadget.I’m am ver...   \n",
       "2   Highly recommended  iphone 11 is a very good phone to buy only if ...   \n",
       "3     Perfect product!  It’s a must buy who is looking for an upgrade ...   \n",
       "4            Brilliant  The Best Phone for the MoneyThe iPhone 11 offe...   \n",
       "..                 ...                                                ...   \n",
       "95           Brilliant  I have migrated from OP 7pro... and trust me, ...   \n",
       "96   Worth every penny  Previously I was using one plus 3t it was a gr...   \n",
       "97           Wonderful  This is my first ever I phone. Before this I w...   \n",
       "98       Great product  Well you all know the specifications . One of ...   \n",
       "99  Highly recommended  It's my first time to use iOS phone and I am l...   \n",
       "\n",
       "   Rating  \n",
       "0       5  \n",
       "1       5  \n",
       "2       5  \n",
       "3       5  \n",
       "4       5  \n",
       "..    ...  \n",
       "95      5  \n",
       "96      5  \n",
       "97      5  \n",
       "98      5  \n",
       "99      5  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Flipkart 100 reviews\")\n",
    "flipkart_reviews()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 Sneakers from Flipkart\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Descr</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINET</td>\n",
       "      <td>Men Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bond Street By Red Tape</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,049</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Casual Sneakers Shoes For Men Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Smart Casuals Canvas Shoes Combo pack of 2 Sne...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Restinfoot</td>\n",
       "      <td>Casual shoes,Sneakers for men's,shoes for men'...</td>\n",
       "      <td>₹369</td>\n",
       "      <td>63% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Aura</td>\n",
       "      <td>Trendy and Stylish Combo Pack of 3 Casual Shoe...</td>\n",
       "      <td>₹699</td>\n",
       "      <td>53% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 4 Canvas Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,258</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Brand  \\\n",
       "0                     VINET   \n",
       "1   Bond Street By Red Tape   \n",
       "2                    Chevit   \n",
       "3              Robbie jones   \n",
       "4       World Wear Footwear   \n",
       "..                      ...   \n",
       "95                   Chevit   \n",
       "96               Restinfoot   \n",
       "97                     Aura   \n",
       "98                   BRUTON   \n",
       "99                 Red Tape   \n",
       "\n",
       "                                        Product Descr   Price Discount %  \n",
       "0                 Men Sneakers Shoes Sneakers For Men    ₹449    55% off  \n",
       "1                                    Sneakers For Men  ₹1,049    70% off  \n",
       "2   Combo Pack of 4 Casual Sneakers With Sneakers ...    ₹449    77% off  \n",
       "3      Casual Sneakers Shoes For Men Sneakers For Men    ₹379    62% off  \n",
       "4   Combo Pack of 4 Latest Collection Stylish Casu...    ₹474    76% off  \n",
       "..                                                ...     ...        ...  \n",
       "95  Smart Casuals Canvas Shoes Combo pack of 2 Sne...    ₹299    70% off  \n",
       "96  Casual shoes,Sneakers for men's,shoes for men'...    ₹369    63% off  \n",
       "97  Trendy and Stylish Combo Pack of 3 Casual Shoe...    ₹699    53% off  \n",
       "98            Combo Pack Of 4 Canvas Sneakers For Men    ₹499    85% off  \n",
       "99                                   Sneakers For Men  ₹1,258    70% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the previously developed Function to capture data giving input as Sneakers\n",
    "print(\"100 Sneakers from Flipkart\")\n",
    "flipkart_product(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of\n",
    "the shoes , Short Shoe description, price of the shoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myntra_shoes():\n",
    "    driver = webdriver.Chrome(\"C:\\\\chromedriver_win32\\\\chromedriver\")\n",
    "    driver.get(\"https://www.myntra.com/shoes\")\n",
    "    \n",
    "    # Clicking filters for Price\n",
    "    for i in driver.find_elements_by_xpath(\"//label[@class='common-customCheckbox vertical-filters-label']\"):\n",
    "        if 'Rs. 6589 to Rs. 13059' in i.text: \n",
    "            filter_button = i.find_element(By.CLASS_NAME,'common-checkboxIndicator')\n",
    "            filter_button.click()\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Clicking filters for Color Black\n",
    "    for i in driver.find_elements_by_xpath(\"//label[@class='common-customCheckbox']\"):\n",
    "        if 'Black' in i.text: \n",
    "            filter_button = i.find_element(By.CLASS_NAME,'common-checkboxIndicator')\n",
    "            filter_button.click()\n",
    "    df_shoes = pd.DataFrame({})\n",
    "    while len(df_shoes) < 100:   # Capture data till length 100\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        Brand = []\n",
    "        for i in soup.find_all('h3',class_=\"product-brand\"):\n",
    "            Brand.append(i.text)\n",
    "        Short_Desc = []\n",
    "        for i in soup.find_all('h4',class_=\"product-product\"):\n",
    "            Short_Desc.append(i.text)\n",
    "        Price = []\n",
    "        for i in soup.find_all('div',class_=\"product-productMetaInfo\"):\n",
    "            if i.find('span',class_=\"product-discountedPrice\") == None:\n",
    "                Price.append(i.find('div',class_=\"product-price\").text)\n",
    "            else:\n",
    "                Price.append(i.find('span',class_=\"product-discountedPrice\").text)\n",
    "        df = pd.DataFrame({})\n",
    "        df[\"Brand\"] = Brand\n",
    "        df[\"Short Description\"] = Short_Desc\n",
    "        df[\"Price\"] = Price\n",
    "        df_shoes = df_shoes.append(df)\n",
    "        df_shoes = df_shoes.reset_index(drop=True)\n",
    "        \n",
    "        # Going next page\n",
    "        nxt_button=driver.find_element_by_xpath(\"//li[@class='pagination-next']\")\n",
    "        if nxt_button.text=='Next':\n",
    "            nxt_button.click()\n",
    "        time.sleep(5)\n",
    "    return df_shoes[:100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black Shoes Myntra -- Price range (Rs. 6589 to Rs. 13059)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "      <td>Rs. 9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men HYBRID NETFIT Running Shoe</td>\n",
       "      <td>Rs. 6599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Men Leather Formal Oxfords</td>\n",
       "      <td>Rs. 12490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men SOLAR DRIVE 19 M Running</td>\n",
       "      <td>Rs. 8399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM VOMERO Running</td>\n",
       "      <td>Rs. 10796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Leather Slip-On Shoes</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>FILA</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 8499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Slip-Ons</td>\n",
       "      <td>Rs. 6990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Charged Rogue 2 Wide 2E Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>UNDER ARMOUR</td>\n",
       "      <td>Men Charged Escape 3 Evo</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Brand                  Short Description      Price\n",
       "0           Geox          Men Leather Driving Shoes   Rs. 9999\n",
       "1           Puma     Men HYBRID NETFIT Running Shoe   Rs. 6599\n",
       "2           Geox         Men Leather Formal Oxfords  Rs. 12490\n",
       "3         ADIDAS       Men SOLAR DRIVE 19 M Running   Rs. 8399\n",
       "4           Nike        Men AIR ZOOM VOMERO Running  Rs. 10796\n",
       "..           ...                                ...        ...\n",
       "95         Ruosh          Men Leather Slip-On Shoes   Rs. 6990\n",
       "96          FILA                  Men Running Shoes   Rs. 8499\n",
       "97         Ruosh  Men Solid Leather Formal Slip-Ons   Rs. 6990\n",
       "98  UNDER ARMOUR      Charged Rogue 2 Wide 2E Shoes   Rs. 7999\n",
       "99  UNDER ARMOUR           Men Charged Escape 3 Evo   Rs. 8999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Black Shoes Myntra -- Price range (Rs. 6589 to Rs. 13059)\")\n",
    "myntra_shoes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    " Enter “Laptop” in the search field and then click the search icon.\n",
    " Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” as shown in the\n",
    "below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Function\n",
    "def Amazon_laptop():\n",
    "    driver = webdriver.Chrome(\"C:\\\\chromedriver_win32\\\\chromedriver\")\n",
    "    driver.get(\"https://www.amazon.in/\")\n",
    "    \n",
    "    # Finding element Laptop\n",
    "    driver.find_element_by_id(\"twotabsearchtextbox\").send_keys(\"Laptop\")\n",
    "    driver.find_element_by_id(\"nav-search-submit-button\").click()\n",
    "    filter_search = driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # Clicking filter for \"Intel Core i7\"\n",
    "    temp = 0\n",
    "    for item in filter_search:\n",
    "        check = item.find_elements_by_xpath(\"//span[@class='a-size-base a-color-base']\")\n",
    "        for i in check: \n",
    "            if \"Intel Core i7\" in i.text:\n",
    "                i.click()\n",
    "                temp = 1\n",
    "                break\n",
    "        if temp == 1:\n",
    "            break\n",
    "    temp = 0\n",
    "    \n",
    "    # Clicking filter for \"Intel Core i7\"\n",
    "    for item in filter_search:\n",
    "        check = item.find_elements_by_xpath(\"//span[@class='a-size-base a-color-base']\")\n",
    "        for i in check: \n",
    "            if \"Intel Core i9\" in i.text:\n",
    "                i.click()\n",
    "                temp = 1\n",
    "                break\n",
    "        if temp == 1:\n",
    "            break\n",
    "        \n",
    "    time.sleep(3)  # Using sleep so that page gets time to Load\n",
    "    soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "    Title = []\n",
    "    for i in soup.find_all('span',class_=\"a-size-medium a-color-base a-text-normal\"):\n",
    "        Title.append(i.text)\n",
    "    Rating = []\n",
    "    for i in soup.find_all('span',class_=\"a-icon-alt\"):\n",
    "        Rating.append(i.text) \n",
    "    Price = []\n",
    "    for i in soup.find_all('span',class_=\"a-price-whole\"):\n",
    "        Price.append(i.text)\n",
    "    Amazon_df = pd.DataFrame({})\n",
    "    Amazon_df[\"Title\"] = Title[:10]\n",
    "    Amazon_df[\"Rating\"] = Rating[:10]\n",
    "    Amazon_df[\"Price\"] = Price[:10]\n",
    "    return Amazon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Laptops from Amazon with filters applied for Intel Core i9/i7 processor CPU\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4 Stars &amp; Up</td>\n",
       "      <td>50,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dell Alienware m15(R3) 15.6-inch FHD Gaming La...</td>\n",
       "      <td>3 Stars &amp; Up</td>\n",
       "      <td>1,97,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...</td>\n",
       "      <td>2 Stars &amp; Up</td>\n",
       "      <td>1,09,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...</td>\n",
       "      <td>1 Star &amp; Up</td>\n",
       "      <td>74,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP 14 Thin &amp; Light 14-inch FHD Laptop (11th Ge...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>75,482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ROG Zephyrus M15 (2020), 15.6\" 4K UHD, In...</td>\n",
       "      <td>2.7 out of 5 stars</td>\n",
       "      <td>1,49,099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Acer Nitro 5 Intel i7 - 9th Gen 17.3-inch Disp...</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>74,986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell G3 3500 Gaming 15.6inch 120hz FHD Display...</td>\n",
       "      <td>3.5 out of 5 stars</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>95,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo Legion 5i 10th Gen Intel Core i7 15.6 i...</td>\n",
       "      <td>1.8 out of 5 stars</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title              Rating  \\\n",
       "0  Mi Notebook Horizon Edition 14 Intel Core i5-1...        4 Stars & Up   \n",
       "1  Dell Alienware m15(R3) 15.6-inch FHD Gaming La...        3 Stars & Up   \n",
       "2  Lenovo Yoga S740 Intel Core i7 10th Gen 14 inc...        2 Stars & Up   \n",
       "3  HP Pavilion x360 Touchscreen 2-in-1 FHD 14-inc...         1 Star & Up   \n",
       "4  HP 14 Thin & Light 14-inch FHD Laptop (11th Ge...  4.2 out of 5 stars   \n",
       "5  ASUS ROG Zephyrus M15 (2020), 15.6\" 4K UHD, In...  2.7 out of 5 stars   \n",
       "6  Acer Nitro 5 Intel i7 - 9th Gen 17.3-inch Disp...  3.3 out of 5 stars   \n",
       "7  Dell G3 3500 Gaming 15.6inch 120hz FHD Display...  3.5 out of 5 stars   \n",
       "8  ASUS ZenBook 14 (2020) Intel Core i7-1165G7 11...  4.0 out of 5 stars   \n",
       "9  Lenovo Legion 5i 10th Gen Intel Core i7 15.6 i...  1.8 out of 5 stars   \n",
       "\n",
       "      Price  \n",
       "0    50,999  \n",
       "1  1,97,200  \n",
       "2  1,09,990  \n",
       "3    74,990  \n",
       "4    75,482  \n",
       "5  1,49,099  \n",
       "6    74,986  \n",
       "7    77,990  \n",
       "8    95,990  \n",
       "9    89,990  "
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"10 Laptops from Amazon with filters applied for Intel Core i9/i7 processor CPU\")\n",
    "Amazon_laptop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
